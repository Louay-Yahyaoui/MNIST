{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ae7f91",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:02.810173Z",
     "iopub.status.busy": "2023-12-03T15:50:02.809814Z",
     "iopub.status.idle": "2023-12-03T15:50:10.808225Z",
     "shell.execute_reply": "2023-12-03T15:50:10.807099Z"
    },
    "papermill": {
     "duration": 8.008743,
     "end_time": "2023-12-03T15:50:10.810292",
     "exception": false,
     "start_time": "2023-12-03T15:50:02.801549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization, ReLU\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d631a",
   "metadata": {
    "papermill": {
     "duration": 0.006427,
     "end_time": "2023-12-03T15:50:10.823539",
     "exception": false,
     "start_time": "2023-12-03T15:50:10.817112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9245ec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:10.837770Z",
     "iopub.status.busy": "2023-12-03T15:50:10.837179Z",
     "iopub.status.idle": "2023-12-03T15:50:16.658834Z",
     "shell.execute_reply": "2023-12-03T15:50:16.657804Z"
    },
    "papermill": {
     "duration": 5.831332,
     "end_time": "2023-12-03T15:50:16.661209",
     "exception": false,
     "start_time": "2023-12-03T15:50:10.829877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "X_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b434eedd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:16.676720Z",
     "iopub.status.busy": "2023-12-03T15:50:16.676397Z",
     "iopub.status.idle": "2023-12-03T15:50:16.762498Z",
     "shell.execute_reply": "2023-12-03T15:50:16.761498Z"
    },
    "papermill": {
     "duration": 0.096418,
     "end_time": "2023-12-03T15:50:16.764755",
     "exception": false,
     "start_time": "2023-12-03T15:50:16.668337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = train_data[\"label\"]\n",
    "X = train_data.drop(\"label\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1f971",
   "metadata": {
    "papermill": {
     "duration": 0.006421,
     "end_time": "2023-12-03T15:50:16.778629",
     "exception": false,
     "start_time": "2023-12-03T15:50:16.772208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235392e0",
   "metadata": {
    "papermill": {
     "duration": 0.006281,
     "end_time": "2023-12-03T15:50:16.791362",
     "exception": false,
     "start_time": "2023-12-03T15:50:16.785081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is 784 pixels (28*28) and it's in grayscale so the input to the model is going to be 28 * 28 * 1 as it only has one channel.\n",
    "It also helps for the data to be between 0 and 1 instead of 0 and 255 as it helps the model converge faster and wouldn't have massive gradients at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5722325f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:16.805724Z",
     "iopub.status.busy": "2023-12-03T15:50:16.805444Z",
     "iopub.status.idle": "2023-12-03T15:50:20.178727Z",
     "shell.execute_reply": "2023-12-03T15:50:20.177898Z"
    },
    "papermill": {
     "duration": 3.382979,
     "end_time": "2023-12-03T15:50:20.180990",
     "exception": false,
     "start_time": "2023-12-03T15:50:16.798011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting dataframe to tensorflow tensor then scaling the data to [0,1]\n",
    "X = tf.convert_to_tensor(X, tf.float64) / 255.0\n",
    "X_test = tf.convert_to_tensor(X_test, tf.float64) / 255.0\n",
    "y = tf.convert_to_tensor(y)\n",
    "X = tf.reshape(X, (-1, 28, 28, 1))\n",
    "X_test = tf.reshape(X_test, (-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60326ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.195472Z",
     "iopub.status.busy": "2023-12-03T15:50:20.195156Z",
     "iopub.status.idle": "2023-12-03T15:50:20.210668Z",
     "shell.execute_reply": "2023-12-03T15:50:20.209937Z"
    },
    "papermill": {
     "duration": 0.024857,
     "end_time": "2023-12-03T15:50:20.212568",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.187711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n1 = int(X.shape[0]*.9)\n",
    "X_train, y_train = X[:n1], y[:n1]\n",
    "X_valid, y_valid = X[n1:], y[n1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b174c5",
   "metadata": {
    "papermill": {
     "duration": 0.006254,
     "end_time": "2023-12-03T15:50:20.225266",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.219012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdc91b",
   "metadata": {
    "papermill": {
     "duration": 0.006192,
     "end_time": "2023-12-03T15:50:20.237970",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.231778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A basic CNN with 2 conv layers and 2 hidden layers, I use dropout on every single layer with p = 0.3 except for the input where I have found that it hinders performance. \n",
    "\n",
    "There is some data augmentation as well with a random rotation below 10Â° and a random translation between 0 and .1 in both dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a822ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.251828Z",
     "iopub.status.busy": "2023-12-03T15:50:20.251550Z",
     "iopub.status.idle": "2023-12-03T15:50:20.255625Z",
     "shell.execute_reply": "2023-12-03T15:50:20.254672Z"
    },
    "papermill": {
     "duration": 0.01338,
     "end_time": "2023-12-03T15:50:20.257685",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.244305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel_size  = 3\n",
    "dropout_rate = 0.3 #.25 in prev experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1297e74c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.271605Z",
     "iopub.status.busy": "2023-12-03T15:50:20.271316Z",
     "iopub.status.idle": "2023-12-03T15:50:20.281590Z",
     "shell.execute_reply": "2023-12-03T15:50:20.280738Z"
    },
    "papermill": {
     "duration": 0.019381,
     "end_time": "2023-12-03T15:50:20.283514",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.264133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNIST(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training = True\n",
    "        \n",
    "        # Data augmentation\n",
    "        self.translate = tf.keras.layers.RandomTranslation(.05, .05)\n",
    "        self.rotate = tf.keras.layers.RandomRotation(.05)\n",
    "        \n",
    "        self.conv1 = Conv2D(6, 5, activation = \"relu\")\n",
    "        self.pool1 = MaxPooling2D()\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv2 = Conv2D(16, 3, activation = \"relu\")\n",
    "        #self.pool2 = MaxPooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.ln1 = Dense(256, activation = \"relu\")\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.ln2 = Dense(64, activation = \"relu\")\n",
    "        self.dropout4 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.out = Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "            \n",
    "        x = self.translate(x, training = self.training)\n",
    "        x = self.rotate(x, training = self.training)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x, training = self.training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        #x = self.pool2(x)\n",
    "        x = self.dropout2(x, training = self.training)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout3(x, training = self.training)\n",
    "        \n",
    "        x = self.ln2(x)\n",
    "        x = self.dropout4(x, training = self.training)\n",
    "        \n",
    "        out = self.out(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bead3f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.297330Z",
     "iopub.status.busy": "2023-12-03T15:50:20.297069Z",
     "iopub.status.idle": "2023-12-03T15:50:20.604241Z",
     "shell.execute_reply": "2023-12-03T15:50:20.603188Z"
    },
    "papermill": {
     "duration": 0.324127,
     "end_time": "2023-12-03T15:50:20.614103",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.289976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_translation (RandomT  multiple                 0         \n",
      " ranslation)                                                     \n",
      "                                                                 \n",
      " random_rotation (RandomRota  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d (Conv2D)             multiple                  156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  880       \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  409856    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  16448     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 427,990\n",
      "Trainable params: 427,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= MNIST()\n",
    "model.build((None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901877f",
   "metadata": {
    "papermill": {
     "duration": 0.008985,
     "end_time": "2023-12-03T15:50:20.632522",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.623537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dropout paper claims that decaying learning rate works best for NNs with dropout so that's why I chose exponential decay. As for the actual values, several were tested and this seemed to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156b95e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.652130Z",
     "iopub.status.busy": "2023-12-03T15:50:20.651824Z",
     "iopub.status.idle": "2023-12-03T15:50:20.659876Z",
     "shell.execute_reply": "2023-12-03T15:50:20.659131Z"
    },
    "papermill": {
     "duration": 0.020034,
     "end_time": "2023-12-03T15:50:20.661769",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.641735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70badaa",
   "metadata": {
    "papermill": {
     "duration": 0.00896,
     "end_time": "2023-12-03T15:50:20.679984",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.671024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I use the training and testing steps straight from the tensorflow docs with minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbd1b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.699338Z",
     "iopub.status.busy": "2023-12-03T15:50:20.699055Z",
     "iopub.status.idle": "2023-12-03T15:50:20.705079Z",
     "shell.execute_reply": "2023-12-03T15:50:20.704216Z"
    },
    "papermill": {
     "duration": 0.018034,
     "end_time": "2023-12-03T15:50:20.707136",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.689102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X:tf.Tensor, y:tf.Tensor):\n",
    "    model.training = True\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(X)\n",
    "        loss = loss_fn(y, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66410cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.726836Z",
     "iopub.status.busy": "2023-12-03T15:50:20.726548Z",
     "iopub.status.idle": "2023-12-03T15:50:20.731323Z",
     "shell.execute_reply": "2023-12-03T15:50:20.730475Z"
    },
    "papermill": {
     "duration": 0.01651,
     "end_time": "2023-12-03T15:50:20.733170",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.716660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    model.training = False\n",
    "    predictions = model(images)\n",
    "    loss = loss_fn(labels, predictions)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca6657",
   "metadata": {
    "papermill": {
     "duration": 0.008893,
     "end_time": "2023-12-03T15:50:20.751256",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.742363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I used a fairly typical training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42cedd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.770729Z",
     "iopub.status.busy": "2023-12-03T15:50:20.770487Z",
     "iopub.status.idle": "2023-12-03T15:50:20.774224Z",
     "shell.execute_reply": "2023-12-03T15:50:20.773377Z"
    },
    "papermill": {
     "duration": 0.015671,
     "end_time": "2023-12-03T15:50:20.776098",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.760427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6e4b64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:20.795677Z",
     "iopub.status.busy": "2023-12-03T15:50:20.795387Z",
     "iopub.status.idle": "2023-12-03T15:50:21.013419Z",
     "shell.execute_reply": "2023-12-03T15:50:21.012614Z"
    },
    "papermill": {
     "duration": 0.23038,
     "end_time": "2023-12-03T15:50:21.015609",
     "exception": false,
     "start_time": "2023-12-03T15:50:20.785229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "data = data.shuffle(buffer_size = len(X_train), reshuffle_each_iteration = True, \n",
    "                          seed = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4073f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:50:21.036484Z",
     "iopub.status.busy": "2023-12-03T15:50:21.035944Z",
     "iopub.status.idle": "2023-12-03T15:55:00.374311Z",
     "shell.execute_reply": "2023-12-03T15:55:00.373252Z"
    },
    "papermill": {
     "duration": 279.350697,
     "end_time": "2023-12-03T15:55:00.376471",
     "exception": false,
     "start_time": "2023-12-03T15:50:21.025774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:50:22.726100: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmnist/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-12-03 15:50:31.540639: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmnist/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500: loss: 1.52443, val_loss: 0.39706, val_accuracy: 0.90119\n",
      "Epoch 2/500: loss: 0.74127, val_loss: 0.20583, val_accuracy: 0.94071\n",
      "Epoch 3/500: loss: 0.52166, val_loss: 0.14377, val_accuracy: 0.95500\n",
      "Epoch 4/500: loss: 0.41157, val_loss: 0.10754, val_accuracy: 0.96524\n",
      "Epoch 5/500: loss: 0.34664, val_loss: 0.08998, val_accuracy: 0.96905\n",
      "Epoch 6/500: loss: 0.29924, val_loss: 0.07976, val_accuracy: 0.97310\n",
      "Epoch 7/500: loss: 0.27395, val_loss: 0.07401, val_accuracy: 0.97452\n",
      "Epoch 8/500: loss: 0.25506, val_loss: 0.06641, val_accuracy: 0.97714\n",
      "Epoch 9/500: loss: 0.23107, val_loss: 0.06231, val_accuracy: 0.97810\n",
      "Epoch 10/500: loss: 0.21631, val_loss: 0.06105, val_accuracy: 0.97976\n",
      "Epoch 11/500: loss: 0.20558, val_loss: 0.05623, val_accuracy: 0.98048\n",
      "Epoch 12/500: loss: 0.19616, val_loss: 0.04935, val_accuracy: 0.98381\n",
      "Epoch 13/500: loss: 0.18697, val_loss: 0.04780, val_accuracy: 0.98357\n",
      "Epoch 14/500: loss: 0.18055, val_loss: 0.04543, val_accuracy: 0.98333\n",
      "Epoch 15/500: loss: 0.17166, val_loss: 0.04500, val_accuracy: 0.98476\n",
      "Epoch 16/500: loss: 0.16379, val_loss: 0.04506, val_accuracy: 0.98548\n",
      "Epoch 17/500: loss: 0.15674, val_loss: 0.04065, val_accuracy: 0.98714\n",
      "Epoch 18/500: loss: 0.15378, val_loss: 0.04191, val_accuracy: 0.98619\n",
      "Epoch 19/500: loss: 0.14778, val_loss: 0.03765, val_accuracy: 0.98810\n",
      "Epoch 20/500: loss: 0.14009, val_loss: 0.03690, val_accuracy: 0.98833\n",
      "Epoch 21/500: loss: 0.13910, val_loss: 0.03735, val_accuracy: 0.98786\n",
      "Epoch 22/500: loss: 0.13284, val_loss: 0.03353, val_accuracy: 0.98929\n",
      "Epoch 23/500: loss: 0.13074, val_loss: 0.03352, val_accuracy: 0.99024\n",
      "Epoch 24/500: loss: 0.13121, val_loss: 0.03326, val_accuracy: 0.98952\n",
      "Epoch 25/500: loss: 0.12755, val_loss: 0.03108, val_accuracy: 0.99048\n",
      "Epoch 26/500: loss: 0.12514, val_loss: 0.03516, val_accuracy: 0.98857\n",
      "Epoch 27/500: loss: 0.12325, val_loss: 0.03253, val_accuracy: 0.98929\n",
      "Epoch 28/500: loss: 0.11898, val_loss: 0.02948, val_accuracy: 0.99119\n",
      "Epoch 29/500: loss: 0.11656, val_loss: 0.03055, val_accuracy: 0.99048\n",
      "Epoch 30/500: loss: 0.11423, val_loss: 0.03261, val_accuracy: 0.98905\n",
      "Epoch 31/500: loss: 0.11042, val_loss: 0.02969, val_accuracy: 0.99119\n",
      "Epoch 32/500: loss: 0.10940, val_loss: 0.02993, val_accuracy: 0.99048\n",
      "Epoch 33/500: loss: 0.11034, val_loss: 0.02573, val_accuracy: 0.99143\n",
      "Epoch 34/500: loss: 0.10478, val_loss: 0.02805, val_accuracy: 0.99119\n",
      "Epoch 35/500: loss: 0.10576, val_loss: 0.02686, val_accuracy: 0.99143\n",
      "Epoch 36/500: loss: 0.10799, val_loss: 0.02633, val_accuracy: 0.99048\n",
      "Epoch 37/500: loss: 0.09733, val_loss: 0.02377, val_accuracy: 0.99190\n",
      "Epoch 38/500: loss: 0.09791, val_loss: 0.02440, val_accuracy: 0.99238\n",
      "Epoch 39/500: loss: 0.10057, val_loss: 0.02439, val_accuracy: 0.99214\n",
      "Epoch 40/500: loss: 0.09444, val_loss: 0.02559, val_accuracy: 0.99310\n",
      "Epoch 41/500: loss: 0.09430, val_loss: 0.02407, val_accuracy: 0.99214\n",
      "Epoch 42/500: loss: 0.09762, val_loss: 0.02176, val_accuracy: 0.99357\n",
      "Epoch 43/500: loss: 0.09565, val_loss: 0.02302, val_accuracy: 0.99310\n",
      "Epoch 44/500: loss: 0.09248, val_loss: 0.02489, val_accuracy: 0.99286\n",
      "Epoch 45/500: loss: 0.09075, val_loss: 0.02316, val_accuracy: 0.99262\n",
      "Epoch 46/500: loss: 0.09022, val_loss: 0.02307, val_accuracy: 0.99333\n",
      "Epoch 47/500: loss: 0.08615, val_loss: 0.02254, val_accuracy: 0.99381\n",
      "Epoch 48/500: loss: 0.08842, val_loss: 0.02419, val_accuracy: 0.99357\n",
      "Epoch 49/500: loss: 0.08718, val_loss: 0.02441, val_accuracy: 0.99143\n",
      "Epoch 50/500: loss: 0.08715, val_loss: 0.02415, val_accuracy: 0.99214\n",
      "Epoch 51/500: loss: 0.08757, val_loss: 0.02319, val_accuracy: 0.99357\n",
      "Epoch 52/500: loss: 0.08611, val_loss: 0.01991, val_accuracy: 0.99357\n",
      "Epoch 53/500: loss: 0.08146, val_loss: 0.01980, val_accuracy: 0.99357\n",
      "Epoch 54/500: loss: 0.08411, val_loss: 0.02073, val_accuracy: 0.99333\n",
      "Epoch 55/500: loss: 0.08301, val_loss: 0.01984, val_accuracy: 0.99310\n",
      "Epoch 56/500: loss: 0.08383, val_loss: 0.02010, val_accuracy: 0.99381\n",
      "Epoch 57/500: loss: 0.07857, val_loss: 0.01913, val_accuracy: 0.99405\n",
      "Epoch 58/500: loss: 0.08084, val_loss: 0.02091, val_accuracy: 0.99333\n",
      "Epoch 59/500: loss: 0.08120, val_loss: 0.02046, val_accuracy: 0.99238\n",
      "Epoch 60/500: loss: 0.07912, val_loss: 0.01929, val_accuracy: 0.99476\n",
      "Epoch 61/500: loss: 0.07616, val_loss: 0.01950, val_accuracy: 0.99357\n",
      "Epoch 62/500: loss: 0.07460, val_loss: 0.01959, val_accuracy: 0.99452\n",
      "Epoch 63/500: loss: 0.07635, val_loss: 0.02351, val_accuracy: 0.99286\n",
      "Epoch 64/500: loss: 0.07672, val_loss: 0.02054, val_accuracy: 0.99429\n",
      "Epoch 65/500: loss: 0.07325, val_loss: 0.02106, val_accuracy: 0.99357\n",
      "Epoch 66/500: loss: 0.07575, val_loss: 0.01724, val_accuracy: 0.99476\n",
      "Epoch 67/500: loss: 0.07195, val_loss: 0.01964, val_accuracy: 0.99286\n",
      "Epoch 68/500: loss: 0.07382, val_loss: 0.01936, val_accuracy: 0.99405\n",
      "Epoch 69/500: loss: 0.07366, val_loss: 0.01785, val_accuracy: 0.99405\n",
      "Epoch 70/500: loss: 0.07445, val_loss: 0.01844, val_accuracy: 0.99429\n",
      "Epoch 71/500: loss: 0.07159, val_loss: 0.01857, val_accuracy: 0.99452\n",
      "Epoch 72/500: loss: 0.07358, val_loss: 0.01903, val_accuracy: 0.99452\n",
      "Epoch 73/500: loss: 0.07102, val_loss: 0.01768, val_accuracy: 0.99452\n",
      "Epoch 74/500: loss: 0.06990, val_loss: 0.01685, val_accuracy: 0.99476\n",
      "Epoch 75/500: loss: 0.07179, val_loss: 0.01870, val_accuracy: 0.99333\n",
      "Epoch 76/500: loss: 0.07218, val_loss: 0.01688, val_accuracy: 0.99429\n",
      "Epoch 77/500: loss: 0.06697, val_loss: 0.01652, val_accuracy: 0.99405\n",
      "Epoch 78/500: loss: 0.06875, val_loss: 0.01649, val_accuracy: 0.99548\n",
      "Epoch 79/500: loss: 0.06839, val_loss: 0.01898, val_accuracy: 0.99333\n",
      "Epoch 80/500: loss: 0.06539, val_loss: 0.01668, val_accuracy: 0.99429\n",
      "Epoch 81/500: loss: 0.06600, val_loss: 0.01772, val_accuracy: 0.99238\n",
      "Epoch 82/500: loss: 0.06677, val_loss: 0.01745, val_accuracy: 0.99476\n",
      "Epoch 83/500: loss: 0.06736, val_loss: 0.01771, val_accuracy: 0.99452\n",
      "Epoch 84/500: loss: 0.06576, val_loss: 0.01694, val_accuracy: 0.99548\n",
      "Epoch 85/500: loss: 0.06551, val_loss: 0.01767, val_accuracy: 0.99452\n",
      "Epoch 86/500: loss: 0.06792, val_loss: 0.01893, val_accuracy: 0.99429\n",
      "Epoch 87/500: loss: 0.06523, val_loss: 0.01722, val_accuracy: 0.99476\n",
      "Epoch 88/500: loss: 0.06850, val_loss: 0.01650, val_accuracy: 0.99500\n",
      "Epoch 89/500: loss: 0.06381, val_loss: 0.01786, val_accuracy: 0.99452\n",
      "Epoch 90/500: loss: 0.06066, val_loss: 0.01621, val_accuracy: 0.99571\n",
      "Epoch 91/500: loss: 0.06327, val_loss: 0.01590, val_accuracy: 0.99548\n",
      "Epoch 92/500: loss: 0.06411, val_loss: 0.01617, val_accuracy: 0.99524\n",
      "Epoch 93/500: loss: 0.06242, val_loss: 0.01647, val_accuracy: 0.99524\n",
      "Epoch 94/500: loss: 0.06313, val_loss: 0.01502, val_accuracy: 0.99571\n",
      "Epoch 95/500: loss: 0.06180, val_loss: 0.01614, val_accuracy: 0.99476\n",
      "Epoch 96/500: loss: 0.06471, val_loss: 0.01568, val_accuracy: 0.99595\n",
      "Epoch 97/500: loss: 0.06176, val_loss: 0.01563, val_accuracy: 0.99595\n",
      "Epoch 98/500: loss: 0.06105, val_loss: 0.01541, val_accuracy: 0.99595\n",
      "Epoch 99/500: loss: 0.06281, val_loss: 0.01673, val_accuracy: 0.99524\n",
      "Epoch 100/500: loss: 0.06174, val_loss: 0.01610, val_accuracy: 0.99500\n",
      "Epoch 101/500: loss: 0.05920, val_loss: 0.01605, val_accuracy: 0.99595\n",
      "Epoch 102/500: loss: 0.05965, val_loss: 0.01666, val_accuracy: 0.99643\n",
      "Epoch 103/500: loss: 0.05853, val_loss: 0.01474, val_accuracy: 0.99619\n",
      "Epoch 104/500: loss: 0.05756, val_loss: 0.01454, val_accuracy: 0.99643\n",
      "Epoch 105/500: loss: 0.06047, val_loss: 0.01541, val_accuracy: 0.99619\n",
      "Epoch 106/500: loss: 0.05916, val_loss: 0.01706, val_accuracy: 0.99571\n",
      "Epoch 107/500: loss: 0.05806, val_loss: 0.01612, val_accuracy: 0.99595\n",
      "Epoch 108/500: loss: 0.05706, val_loss: 0.01514, val_accuracy: 0.99571\n",
      "Epoch 109/500: loss: 0.05857, val_loss: 0.01691, val_accuracy: 0.99524\n",
      "Epoch 110/500: loss: 0.05440, val_loss: 0.01703, val_accuracy: 0.99500\n",
      "Epoch 111/500: loss: 0.05557, val_loss: 0.01517, val_accuracy: 0.99571\n",
      "Epoch 112/500: loss: 0.05634, val_loss: 0.01392, val_accuracy: 0.99595\n",
      "Epoch 113/500: loss: 0.05604, val_loss: 0.01462, val_accuracy: 0.99619\n",
      "Epoch 114/500: loss: 0.05324, val_loss: 0.01572, val_accuracy: 0.99476\n",
      "Epoch 115/500: loss: 0.05607, val_loss: 0.01516, val_accuracy: 0.99524\n",
      "Epoch 116/500: loss: 0.05506, val_loss: 0.01404, val_accuracy: 0.99714\n",
      "Epoch 117/500: loss: 0.05326, val_loss: 0.01480, val_accuracy: 0.99619\n",
      "Epoch 118/500: loss: 0.05441, val_loss: 0.01496, val_accuracy: 0.99619\n",
      "Epoch 119/500: loss: 0.05500, val_loss: 0.01517, val_accuracy: 0.99571\n",
      "Epoch 120/500: loss: 0.05501, val_loss: 0.01670, val_accuracy: 0.99500\n",
      "Epoch 121/500: loss: 0.05614, val_loss: 0.01439, val_accuracy: 0.99571\n",
      "Epoch 122/500: loss: 0.05294, val_loss: 0.01378, val_accuracy: 0.99548\n",
      "Epoch 123/500: loss: 0.05594, val_loss: 0.01492, val_accuracy: 0.99571\n",
      "Epoch 124/500: loss: 0.05442, val_loss: 0.01672, val_accuracy: 0.99452\n",
      "Epoch 125/500: loss: 0.05482, val_loss: 0.01419, val_accuracy: 0.99500\n",
      "Epoch 126/500: loss: 0.05438, val_loss: 0.01297, val_accuracy: 0.99571\n",
      "Epoch 127/500: loss: 0.05208, val_loss: 0.01534, val_accuracy: 0.99548\n",
      "Epoch 128/500: loss: 0.05363, val_loss: 0.01645, val_accuracy: 0.99548\n",
      "Epoch 129/500: loss: 0.05258, val_loss: 0.01346, val_accuracy: 0.99595\n",
      "Epoch 130/500: loss: 0.05218, val_loss: 0.01660, val_accuracy: 0.99524\n",
      "Epoch 131/500: loss: 0.05177, val_loss: 0.01527, val_accuracy: 0.99524\n",
      "Epoch 132/500: loss: 0.05368, val_loss: 0.01626, val_accuracy: 0.99500\n",
      "Epoch 133/500: loss: 0.05366, val_loss: 0.01509, val_accuracy: 0.99524\n",
      "Epoch 134/500: loss: 0.05093, val_loss: 0.01499, val_accuracy: 0.99476\n",
      "Epoch 135/500: loss: 0.05013, val_loss: 0.01566, val_accuracy: 0.99476\n",
      "Epoch 136/500: loss: 0.05013, val_loss: 0.01515, val_accuracy: 0.99524\n",
      "Epoch 137/500: loss: 0.05280, val_loss: 0.01358, val_accuracy: 0.99548\n",
      "Epoch 138/500: loss: 0.04895, val_loss: 0.01462, val_accuracy: 0.99548\n",
      "Epoch 139/500: loss: 0.05027, val_loss: 0.01464, val_accuracy: 0.99571\n",
      "Epoch 140/500: loss: 0.05182, val_loss: 0.01740, val_accuracy: 0.99548\n",
      "Epoch 141/500: loss: 0.04917, val_loss: 0.01489, val_accuracy: 0.99452\n",
      "Epoch 142/500: loss: 0.05036, val_loss: 0.01590, val_accuracy: 0.99381\n",
      "Epoch 143/500: loss: 0.05187, val_loss: 0.01648, val_accuracy: 0.99476\n",
      "Epoch 144/500: loss: 0.04946, val_loss: 0.01399, val_accuracy: 0.99548\n",
      "Epoch 145/500: loss: 0.04957, val_loss: 0.01559, val_accuracy: 0.99452\n",
      "Epoch 146/500: loss: 0.04883, val_loss: 0.01368, val_accuracy: 0.99524\n",
      "Epoch 147/500: loss: 0.05032, val_loss: 0.01515, val_accuracy: 0.99524\n",
      "Epoch 148/500: loss: 0.04807, val_loss: 0.01374, val_accuracy: 0.99548\n",
      "Epoch 149/500: loss: 0.05074, val_loss: 0.01320, val_accuracy: 0.99595\n",
      "Epoch 150/500: loss: 0.04681, val_loss: 0.01428, val_accuracy: 0.99548\n",
      "Epoch 151/500: loss: 0.04735, val_loss: 0.01483, val_accuracy: 0.99524\n",
      "Epoch 152/500: loss: 0.04592, val_loss: 0.01528, val_accuracy: 0.99524\n",
      "Epoch 153/500: loss: 0.04842, val_loss: 0.01450, val_accuracy: 0.99619\n",
      "Epoch 154/500: loss: 0.04781, val_loss: 0.01414, val_accuracy: 0.99524\n",
      "Epoch 155/500: loss: 0.04986, val_loss: 0.01429, val_accuracy: 0.99548\n",
      "Epoch 156/500: loss: 0.04688, val_loss: 0.01431, val_accuracy: 0.99548\n",
      "Epoch 157/500: loss: 0.04727, val_loss: 0.01452, val_accuracy: 0.99571\n",
      "Epoch 158/500: loss: 0.05038, val_loss: 0.01483, val_accuracy: 0.99571\n",
      "Epoch 159/500: loss: 0.04849, val_loss: 0.01565, val_accuracy: 0.99548\n",
      "Epoch 160/500: loss: 0.04839, val_loss: 0.01594, val_accuracy: 0.99524\n",
      "Epoch 161/500: loss: 0.04858, val_loss: 0.01434, val_accuracy: 0.99595\n",
      "Epoch 162/500: loss: 0.04842, val_loss: 0.01495, val_accuracy: 0.99548\n",
      "Epoch 163/500: loss: 0.04640, val_loss: 0.01511, val_accuracy: 0.99571\n",
      "Epoch 164/500: loss: 0.04779, val_loss: 0.01543, val_accuracy: 0.99571\n",
      "Epoch 165/500: loss: 0.04919, val_loss: 0.01407, val_accuracy: 0.99571\n",
      "Epoch 166/500: loss: 0.04617, val_loss: 0.01598, val_accuracy: 0.99571\n",
      "Epoch 167/500: loss: 0.04834, val_loss: 0.01633, val_accuracy: 0.99571\n",
      "Epoch 168/500: loss: 0.04626, val_loss: 0.01590, val_accuracy: 0.99667\n",
      "Epoch 169/500: loss: 0.04752, val_loss: 0.01669, val_accuracy: 0.99571\n",
      "Epoch 170/500: loss: 0.04425, val_loss: 0.01563, val_accuracy: 0.99619\n",
      "Epoch 171/500: loss: 0.04532, val_loss: 0.01694, val_accuracy: 0.99571\n",
      "Epoch 172/500: loss: 0.04681, val_loss: 0.01428, val_accuracy: 0.99667\n",
      "Epoch 173/500: loss: 0.04637, val_loss: 0.01518, val_accuracy: 0.99524\n",
      "Epoch 174/500: loss: 0.04478, val_loss: 0.01403, val_accuracy: 0.99643\n",
      "Epoch 175/500: loss: 0.04684, val_loss: 0.01514, val_accuracy: 0.99690\n",
      "Epoch 176/500: loss: 0.04489, val_loss: 0.01455, val_accuracy: 0.99571\n",
      "Epoch 177/500: loss: 0.04628, val_loss: 0.01539, val_accuracy: 0.99524\n",
      "Epoch 178/500: loss: 0.04605, val_loss: 0.01177, val_accuracy: 0.99667\n",
      "Epoch 179/500: loss: 0.04551, val_loss: 0.01385, val_accuracy: 0.99667\n",
      "Epoch 180/500: loss: 0.04686, val_loss: 0.01569, val_accuracy: 0.99548\n",
      "Epoch 181/500: loss: 0.04303, val_loss: 0.01445, val_accuracy: 0.99595\n",
      "Epoch 182/500: loss: 0.04571, val_loss: 0.01469, val_accuracy: 0.99524\n",
      "Epoch 183/500: loss: 0.04568, val_loss: 0.01468, val_accuracy: 0.99548\n",
      "Epoch 184/500: loss: 0.04367, val_loss: 0.01448, val_accuracy: 0.99595\n",
      "Epoch 185/500: loss: 0.04701, val_loss: 0.01429, val_accuracy: 0.99667\n",
      "Epoch 186/500: loss: 0.04496, val_loss: 0.01297, val_accuracy: 0.99619\n",
      "Epoch 187/500: loss: 0.04460, val_loss: 0.01343, val_accuracy: 0.99548\n",
      "Epoch 188/500: loss: 0.04467, val_loss: 0.01386, val_accuracy: 0.99595\n",
      "Epoch 189/500: loss: 0.04597, val_loss: 0.01265, val_accuracy: 0.99643\n",
      "Epoch 190/500: loss: 0.04350, val_loss: 0.01437, val_accuracy: 0.99595\n",
      "Epoch 191/500: loss: 0.04355, val_loss: 0.01388, val_accuracy: 0.99667\n",
      "Epoch 192/500: loss: 0.04354, val_loss: 0.01669, val_accuracy: 0.99524\n",
      "Epoch 193/500: loss: 0.04608, val_loss: 0.01492, val_accuracy: 0.99595\n",
      "Epoch 194/500: loss: 0.04272, val_loss: 0.01629, val_accuracy: 0.99500\n",
      "Epoch 195/500: loss: 0.04248, val_loss: 0.01492, val_accuracy: 0.99619\n",
      "Epoch 196/500: loss: 0.04614, val_loss: 0.01473, val_accuracy: 0.99524\n",
      "Epoch 197/500: loss: 0.04386, val_loss: 0.01546, val_accuracy: 0.99595\n",
      "Epoch 198/500: loss: 0.04244, val_loss: 0.01598, val_accuracy: 0.99548\n",
      "Epoch 199/500: loss: 0.04424, val_loss: 0.01460, val_accuracy: 0.99619\n",
      "Epoch 200/500: loss: 0.04384, val_loss: 0.01569, val_accuracy: 0.99619\n",
      "Epoch 201/500: loss: 0.04569, val_loss: 0.01620, val_accuracy: 0.99595\n",
      "Epoch 202/500: loss: 0.04286, val_loss: 0.01424, val_accuracy: 0.99619\n",
      "Epoch 203/500: loss: 0.04375, val_loss: 0.01417, val_accuracy: 0.99643\n",
      "Epoch 204/500: loss: 0.04272, val_loss: 0.01522, val_accuracy: 0.99595\n",
      "Epoch 205/500: loss: 0.04156, val_loss: 0.01397, val_accuracy: 0.99619\n",
      "Epoch 206/500: loss: 0.04679, val_loss: 0.01338, val_accuracy: 0.99667\n",
      "Epoch 207/500: loss: 0.04011, val_loss: 0.01356, val_accuracy: 0.99619\n",
      "Epoch 208/500: loss: 0.04231, val_loss: 0.01423, val_accuracy: 0.99595\n",
      "Epoch 209/500: loss: 0.04394, val_loss: 0.01494, val_accuracy: 0.99619\n",
      "Epoch 210/500: loss: 0.04361, val_loss: 0.01320, val_accuracy: 0.99643\n",
      "Epoch 211/500: loss: 0.04328, val_loss: 0.01447, val_accuracy: 0.99595\n",
      "Epoch 212/500: loss: 0.04125, val_loss: 0.01567, val_accuracy: 0.99595\n",
      "Epoch 213/500: loss: 0.04282, val_loss: 0.01422, val_accuracy: 0.99571\n",
      "Epoch 214/500: loss: 0.04345, val_loss: 0.01423, val_accuracy: 0.99595\n",
      "Epoch 215/500: loss: 0.03826, val_loss: 0.01486, val_accuracy: 0.99643\n",
      "Epoch 216/500: loss: 0.03974, val_loss: 0.01474, val_accuracy: 0.99643\n",
      "Epoch 217/500: loss: 0.04428, val_loss: 0.01354, val_accuracy: 0.99619\n",
      "Epoch 218/500: loss: 0.04003, val_loss: 0.01428, val_accuracy: 0.99643\n",
      "Epoch 219/500: loss: 0.04265, val_loss: 0.01505, val_accuracy: 0.99571\n",
      "Epoch 220/500: loss: 0.04063, val_loss: 0.01652, val_accuracy: 0.99524\n",
      "Epoch 221/500: loss: 0.04234, val_loss: 0.01558, val_accuracy: 0.99548\n",
      "Epoch 222/500: loss: 0.04180, val_loss: 0.01511, val_accuracy: 0.99524\n",
      "Epoch 223/500: loss: 0.04238, val_loss: 0.01476, val_accuracy: 0.99619\n",
      "Epoch 224/500: loss: 0.04020, val_loss: 0.01535, val_accuracy: 0.99429\n",
      "Epoch 225/500: loss: 0.04534, val_loss: 0.01680, val_accuracy: 0.99500\n",
      "Epoch 226/500: loss: 0.04113, val_loss: 0.01506, val_accuracy: 0.99476\n",
      "Epoch 227/500: loss: 0.04244, val_loss: 0.01479, val_accuracy: 0.99571\n",
      "Epoch 228/500: loss: 0.03927, val_loss: 0.01592, val_accuracy: 0.99571\n",
      "Epoch 229/500: loss: 0.04071, val_loss: 0.01673, val_accuracy: 0.99500\n",
      "Epoch 230/500: loss: 0.04325, val_loss: 0.01553, val_accuracy: 0.99524\n",
      "Epoch 231/500: loss: 0.04060, val_loss: 0.01614, val_accuracy: 0.99595\n",
      "Epoch 232/500: loss: 0.04183, val_loss: 0.01385, val_accuracy: 0.99595\n",
      "Epoch 233/500: loss: 0.04020, val_loss: 0.01633, val_accuracy: 0.99500\n",
      "Epoch 234/500: loss: 0.04359, val_loss: 0.01558, val_accuracy: 0.99524\n",
      "Epoch 235/500: loss: 0.04117, val_loss: 0.01668, val_accuracy: 0.99476\n",
      "Epoch 236/500: loss: 0.04241, val_loss: 0.01612, val_accuracy: 0.99524\n",
      "Epoch 237/500: loss: 0.03990, val_loss: 0.01458, val_accuracy: 0.99548\n",
      "Epoch 238/500: loss: 0.04278, val_loss: 0.01564, val_accuracy: 0.99619\n",
      "Epoch 239/500: loss: 0.04126, val_loss: 0.01569, val_accuracy: 0.99571\n",
      "Epoch 240/500: loss: 0.04135, val_loss: 0.01430, val_accuracy: 0.99571\n",
      "Epoch 241/500: loss: 0.04206, val_loss: 0.01550, val_accuracy: 0.99571\n",
      "Epoch 242/500: loss: 0.04078, val_loss: 0.01561, val_accuracy: 0.99548\n",
      "Epoch 243/500: loss: 0.04058, val_loss: 0.01571, val_accuracy: 0.99476\n",
      "Epoch 244/500: loss: 0.03753, val_loss: 0.01527, val_accuracy: 0.99595\n",
      "Epoch 245/500: loss: 0.04036, val_loss: 0.01420, val_accuracy: 0.99571\n",
      "Epoch 246/500: loss: 0.04161, val_loss: 0.01504, val_accuracy: 0.99571\n",
      "Epoch 247/500: loss: 0.03969, val_loss: 0.01554, val_accuracy: 0.99571\n",
      "Epoch 248/500: loss: 0.03950, val_loss: 0.01577, val_accuracy: 0.99619\n",
      "Epoch 249/500: loss: 0.04177, val_loss: 0.01462, val_accuracy: 0.99595\n",
      "Epoch 250/500: loss: 0.03897, val_loss: 0.01611, val_accuracy: 0.99595\n",
      "Epoch 251/500: loss: 0.03525, val_loss: 0.01535, val_accuracy: 0.99619\n",
      "Epoch 252/500: loss: 0.04095, val_loss: 0.01537, val_accuracy: 0.99571\n",
      "Epoch 253/500: loss: 0.03872, val_loss: 0.01598, val_accuracy: 0.99571\n",
      "Epoch 254/500: loss: 0.04011, val_loss: 0.01429, val_accuracy: 0.99548\n",
      "Epoch 255/500: loss: 0.03874, val_loss: 0.01553, val_accuracy: 0.99619\n",
      "Epoch 256/500: loss: 0.03892, val_loss: 0.01600, val_accuracy: 0.99595\n",
      "Epoch 257/500: loss: 0.03815, val_loss: 0.01583, val_accuracy: 0.99595\n",
      "Epoch 258/500: loss: 0.03958, val_loss: 0.01469, val_accuracy: 0.99619\n",
      "Epoch 259/500: loss: 0.04191, val_loss: 0.01425, val_accuracy: 0.99571\n",
      "Epoch 260/500: loss: 0.03975, val_loss: 0.01450, val_accuracy: 0.99619\n",
      "Epoch 261/500: loss: 0.03838, val_loss: 0.01472, val_accuracy: 0.99595\n",
      "Epoch 262/500: loss: 0.04098, val_loss: 0.01637, val_accuracy: 0.99476\n",
      "Epoch 263/500: loss: 0.03860, val_loss: 0.01547, val_accuracy: 0.99571\n",
      "Epoch 264/500: loss: 0.03967, val_loss: 0.01743, val_accuracy: 0.99595\n",
      "Epoch 265/500: loss: 0.03859, val_loss: 0.01635, val_accuracy: 0.99500\n",
      "Epoch 266/500: loss: 0.04035, val_loss: 0.01610, val_accuracy: 0.99548\n",
      "Epoch 267/500: loss: 0.03782, val_loss: 0.01553, val_accuracy: 0.99500\n",
      "Epoch 268/500: loss: 0.03921, val_loss: 0.01744, val_accuracy: 0.99500\n",
      "Epoch 269/500: loss: 0.03983, val_loss: 0.01721, val_accuracy: 0.99548\n",
      "Epoch 270/500: loss: 0.03831, val_loss: 0.01654, val_accuracy: 0.99571\n",
      "Epoch 271/500: loss: 0.04038, val_loss: 0.01559, val_accuracy: 0.99595\n",
      "Epoch 272/500: loss: 0.03735, val_loss: 0.01653, val_accuracy: 0.99571\n",
      "Epoch 273/500: loss: 0.03955, val_loss: 0.01700, val_accuracy: 0.99595\n",
      "Epoch 274/500: loss: 0.03805, val_loss: 0.01789, val_accuracy: 0.99524\n",
      "Epoch 275/500: loss: 0.03494, val_loss: 0.01828, val_accuracy: 0.99476\n",
      "Epoch 276/500: loss: 0.03837, val_loss: 0.01747, val_accuracy: 0.99548\n",
      "Epoch 277/500: loss: 0.03902, val_loss: 0.01599, val_accuracy: 0.99548\n",
      "Epoch 278/500: loss: 0.03846, val_loss: 0.01662, val_accuracy: 0.99548\n",
      "Epoch 279/500: loss: 0.03892, val_loss: 0.01632, val_accuracy: 0.99619\n",
      "Epoch 280/500: loss: 0.03683, val_loss: 0.01535, val_accuracy: 0.99571\n",
      "Epoch 281/500: loss: 0.03581, val_loss: 0.01616, val_accuracy: 0.99548\n",
      "Epoch 282/500: loss: 0.03697, val_loss: 0.01584, val_accuracy: 0.99571\n",
      "Epoch 283/500: loss: 0.03553, val_loss: 0.01580, val_accuracy: 0.99619\n",
      "Epoch 284/500: loss: 0.03821, val_loss: 0.01556, val_accuracy: 0.99643\n",
      "Epoch 285/500: loss: 0.03909, val_loss: 0.01617, val_accuracy: 0.99571\n",
      "Epoch 286/500: loss: 0.03889, val_loss: 0.01594, val_accuracy: 0.99595\n",
      "Epoch 287/500: loss: 0.03827, val_loss: 0.01438, val_accuracy: 0.99548\n",
      "Epoch 288/500: loss: 0.03695, val_loss: 0.01477, val_accuracy: 0.99595\n",
      "Epoch 289/500: loss: 0.03853, val_loss: 0.01516, val_accuracy: 0.99571\n",
      "Epoch 290/500: loss: 0.03624, val_loss: 0.01785, val_accuracy: 0.99500\n",
      "Epoch 291/500: loss: 0.03873, val_loss: 0.01717, val_accuracy: 0.99500\n",
      "Epoch 292/500: loss: 0.03887, val_loss: 0.01601, val_accuracy: 0.99500\n",
      "Epoch 293/500: loss: 0.03625, val_loss: 0.01468, val_accuracy: 0.99619\n",
      "Epoch 294/500: loss: 0.03832, val_loss: 0.01565, val_accuracy: 0.99595\n",
      "Epoch 295/500: loss: 0.04003, val_loss: 0.01481, val_accuracy: 0.99619\n",
      "Epoch 296/500: loss: 0.03675, val_loss: 0.01656, val_accuracy: 0.99524\n",
      "Epoch 297/500: loss: 0.03739, val_loss: 0.01670, val_accuracy: 0.99595\n",
      "Epoch 298/500: loss: 0.03863, val_loss: 0.01507, val_accuracy: 0.99619\n",
      "Epoch 299/500: loss: 0.03711, val_loss: 0.01528, val_accuracy: 0.99619\n",
      "Epoch 300/500: loss: 0.03940, val_loss: 0.01535, val_accuracy: 0.99619\n",
      "Epoch 301/500: loss: 0.03417, val_loss: 0.01563, val_accuracy: 0.99643\n",
      "Epoch 302/500: loss: 0.03885, val_loss: 0.01549, val_accuracy: 0.99595\n",
      "Epoch 303/500: loss: 0.03349, val_loss: 0.01655, val_accuracy: 0.99548\n",
      "Epoch 304/500: loss: 0.03720, val_loss: 0.01731, val_accuracy: 0.99500\n",
      "Epoch 305/500: loss: 0.03869, val_loss: 0.01562, val_accuracy: 0.99619\n",
      "Epoch 306/500: loss: 0.03770, val_loss: 0.01588, val_accuracy: 0.99595\n",
      "Epoch 307/500: loss: 0.03582, val_loss: 0.01822, val_accuracy: 0.99619\n",
      "Epoch 308/500: loss: 0.03561, val_loss: 0.01738, val_accuracy: 0.99500\n",
      "Epoch 309/500: loss: 0.03357, val_loss: 0.01792, val_accuracy: 0.99571\n",
      "Epoch 310/500: loss: 0.03860, val_loss: 0.01794, val_accuracy: 0.99548\n",
      "Epoch 311/500: loss: 0.03780, val_loss: 0.01629, val_accuracy: 0.99571\n",
      "Epoch 312/500: loss: 0.03653, val_loss: 0.01779, val_accuracy: 0.99571\n",
      "Epoch 313/500: loss: 0.03872, val_loss: 0.01637, val_accuracy: 0.99548\n",
      "Epoch 314/500: loss: 0.03694, val_loss: 0.01644, val_accuracy: 0.99571\n",
      "Epoch 315/500: loss: 0.03947, val_loss: 0.01626, val_accuracy: 0.99595\n",
      "Epoch 316/500: loss: 0.03603, val_loss: 0.01753, val_accuracy: 0.99571\n",
      "Epoch 317/500: loss: 0.03671, val_loss: 0.01565, val_accuracy: 0.99500\n",
      "Epoch 318/500: loss: 0.03804, val_loss: 0.01788, val_accuracy: 0.99500\n",
      "Epoch 319/500: loss: 0.03612, val_loss: 0.01789, val_accuracy: 0.99500\n",
      "Epoch 320/500: loss: 0.03677, val_loss: 0.01796, val_accuracy: 0.99500\n",
      "Epoch 321/500: loss: 0.03636, val_loss: 0.01556, val_accuracy: 0.99571\n",
      "Epoch 322/500: loss: 0.03666, val_loss: 0.01661, val_accuracy: 0.99595\n",
      "Epoch 323/500: loss: 0.03634, val_loss: 0.01832, val_accuracy: 0.99571\n",
      "Epoch 324/500: loss: 0.03462, val_loss: 0.01652, val_accuracy: 0.99643\n",
      "Epoch 325/500: loss: 0.03455, val_loss: 0.01566, val_accuracy: 0.99571\n",
      "Epoch 326/500: loss: 0.03562, val_loss: 0.01646, val_accuracy: 0.99595\n",
      "Epoch 327/500: loss: 0.03727, val_loss: 0.01576, val_accuracy: 0.99571\n",
      "Epoch 328/500: loss: 0.03695, val_loss: 0.01513, val_accuracy: 0.99571\n",
      "Epoch 329/500: loss: 0.03589, val_loss: 0.01459, val_accuracy: 0.99524\n",
      "Epoch 330/500: loss: 0.03493, val_loss: 0.01322, val_accuracy: 0.99619\n",
      "Epoch 331/500: loss: 0.03785, val_loss: 0.01551, val_accuracy: 0.99548\n",
      "Epoch 332/500: loss: 0.03935, val_loss: 0.01452, val_accuracy: 0.99643\n",
      "Epoch 333/500: loss: 0.03550, val_loss: 0.01401, val_accuracy: 0.99619\n",
      "Epoch 334/500: loss: 0.03738, val_loss: 0.01430, val_accuracy: 0.99548\n",
      "Epoch 335/500: loss: 0.03612, val_loss: 0.01484, val_accuracy: 0.99548\n",
      "Epoch 336/500: loss: 0.03330, val_loss: 0.01545, val_accuracy: 0.99571\n",
      "Epoch 337/500: loss: 0.03771, val_loss: 0.01628, val_accuracy: 0.99571\n",
      "Epoch 338/500: loss: 0.03567, val_loss: 0.01477, val_accuracy: 0.99643\n",
      "Epoch 339/500: loss: 0.03853, val_loss: 0.01731, val_accuracy: 0.99595\n",
      "Epoch 340/500: loss: 0.03565, val_loss: 0.01732, val_accuracy: 0.99571\n",
      "Epoch 341/500: loss: 0.03506, val_loss: 0.01807, val_accuracy: 0.99524\n",
      "Epoch 342/500: loss: 0.03736, val_loss: 0.01861, val_accuracy: 0.99571\n",
      "Epoch 343/500: loss: 0.03518, val_loss: 0.01725, val_accuracy: 0.99595\n",
      "Epoch 344/500: loss: 0.03308, val_loss: 0.01614, val_accuracy: 0.99619\n",
      "Epoch 345/500: loss: 0.03307, val_loss: 0.01719, val_accuracy: 0.99619\n",
      "Epoch 346/500: loss: 0.03562, val_loss: 0.01712, val_accuracy: 0.99571\n",
      "Epoch 347/500: loss: 0.03531, val_loss: 0.01615, val_accuracy: 0.99476\n",
      "Epoch 348/500: loss: 0.03353, val_loss: 0.01536, val_accuracy: 0.99571\n",
      "Epoch 349/500: loss: 0.03403, val_loss: 0.01779, val_accuracy: 0.99524\n",
      "Epoch 350/500: loss: 0.03448, val_loss: 0.01620, val_accuracy: 0.99595\n",
      "Epoch 351/500: loss: 0.03406, val_loss: 0.01731, val_accuracy: 0.99619\n",
      "Epoch 352/500: loss: 0.03356, val_loss: 0.01574, val_accuracy: 0.99690\n",
      "Epoch 353/500: loss: 0.03458, val_loss: 0.01697, val_accuracy: 0.99571\n",
      "Epoch 354/500: loss: 0.03612, val_loss: 0.01663, val_accuracy: 0.99548\n",
      "Epoch 355/500: loss: 0.03471, val_loss: 0.01668, val_accuracy: 0.99548\n",
      "Epoch 356/500: loss: 0.03567, val_loss: 0.01572, val_accuracy: 0.99571\n",
      "Epoch 357/500: loss: 0.03389, val_loss: 0.01795, val_accuracy: 0.99500\n",
      "Epoch 358/500: loss: 0.03283, val_loss: 0.01771, val_accuracy: 0.99524\n",
      "Epoch 359/500: loss: 0.03555, val_loss: 0.01784, val_accuracy: 0.99500\n",
      "Epoch 360/500: loss: 0.03416, val_loss: 0.01744, val_accuracy: 0.99619\n",
      "Epoch 361/500: loss: 0.03652, val_loss: 0.01850, val_accuracy: 0.99524\n",
      "Epoch 362/500: loss: 0.03651, val_loss: 0.01815, val_accuracy: 0.99571\n",
      "Epoch 363/500: loss: 0.03516, val_loss: 0.01943, val_accuracy: 0.99524\n",
      "Epoch 364/500: loss: 0.03464, val_loss: 0.01727, val_accuracy: 0.99619\n",
      "Epoch 365/500: loss: 0.03364, val_loss: 0.01651, val_accuracy: 0.99595\n",
      "Epoch 366/500: loss: 0.03294, val_loss: 0.01545, val_accuracy: 0.99643\n",
      "Epoch 367/500: loss: 0.03332, val_loss: 0.01428, val_accuracy: 0.99595\n",
      "Epoch 368/500: loss: 0.03267, val_loss: 0.01485, val_accuracy: 0.99643\n",
      "Epoch 369/500: loss: 0.03497, val_loss: 0.01789, val_accuracy: 0.99595\n",
      "Epoch 370/500: loss: 0.03539, val_loss: 0.01690, val_accuracy: 0.99595\n",
      "Epoch 371/500: loss: 0.03414, val_loss: 0.01605, val_accuracy: 0.99595\n",
      "Epoch 372/500: loss: 0.03516, val_loss: 0.01492, val_accuracy: 0.99595\n",
      "Epoch 373/500: loss: 0.03589, val_loss: 0.01426, val_accuracy: 0.99643\n",
      "Epoch 374/500: loss: 0.03601, val_loss: 0.01617, val_accuracy: 0.99595\n",
      "Epoch 375/500: loss: 0.03432, val_loss: 0.01429, val_accuracy: 0.99595\n",
      "Epoch 376/500: loss: 0.03466, val_loss: 0.01455, val_accuracy: 0.99595\n",
      "Epoch 377/500: loss: 0.03660, val_loss: 0.01500, val_accuracy: 0.99643\n",
      "Epoch 378/500: loss: 0.03546, val_loss: 0.01576, val_accuracy: 0.99595\n",
      "Epoch 379/500: loss: 0.03541, val_loss: 0.01647, val_accuracy: 0.99548\n",
      "Epoch 380/500: loss: 0.03245, val_loss: 0.01564, val_accuracy: 0.99619\n",
      "Epoch 381/500: loss: 0.03438, val_loss: 0.01569, val_accuracy: 0.99571\n",
      "Epoch 382/500: loss: 0.03331, val_loss: 0.01570, val_accuracy: 0.99548\n",
      "Epoch 383/500: loss: 0.03307, val_loss: 0.01581, val_accuracy: 0.99619\n",
      "Epoch 384/500: loss: 0.03254, val_loss: 0.01612, val_accuracy: 0.99595\n",
      "Epoch 385/500: loss: 0.03319, val_loss: 0.01415, val_accuracy: 0.99643\n",
      "Epoch 386/500: loss: 0.03438, val_loss: 0.01516, val_accuracy: 0.99571\n",
      "Epoch 387/500: loss: 0.03377, val_loss: 0.01511, val_accuracy: 0.99619\n",
      "Epoch 388/500: loss: 0.03490, val_loss: 0.01468, val_accuracy: 0.99667\n",
      "Epoch 389/500: loss: 0.03556, val_loss: 0.01485, val_accuracy: 0.99690\n",
      "Epoch 390/500: loss: 0.03438, val_loss: 0.01424, val_accuracy: 0.99643\n",
      "Epoch 391/500: loss: 0.03180, val_loss: 0.01515, val_accuracy: 0.99643\n",
      "Epoch 392/500: loss: 0.03319, val_loss: 0.01491, val_accuracy: 0.99643\n",
      "Epoch 393/500: loss: 0.03146, val_loss: 0.01586, val_accuracy: 0.99619\n",
      "Epoch 394/500: loss: 0.03396, val_loss: 0.01626, val_accuracy: 0.99595\n",
      "Epoch 395/500: loss: 0.03207, val_loss: 0.01595, val_accuracy: 0.99571\n",
      "Epoch 396/500: loss: 0.03363, val_loss: 0.01602, val_accuracy: 0.99667\n",
      "Epoch 397/500: loss: 0.03628, val_loss: 0.01583, val_accuracy: 0.99619\n",
      "Epoch 398/500: loss: 0.03219, val_loss: 0.01546, val_accuracy: 0.99643\n",
      "Epoch 399/500: loss: 0.03764, val_loss: 0.01495, val_accuracy: 0.99643\n",
      "Epoch 400/500: loss: 0.03539, val_loss: 0.01529, val_accuracy: 0.99643\n",
      "Epoch 401/500: loss: 0.03556, val_loss: 0.01523, val_accuracy: 0.99643\n",
      "Epoch 402/500: loss: 0.03267, val_loss: 0.01371, val_accuracy: 0.99690\n",
      "Epoch 403/500: loss: 0.03434, val_loss: 0.01470, val_accuracy: 0.99667\n",
      "Epoch 404/500: loss: 0.03428, val_loss: 0.01509, val_accuracy: 0.99643\n",
      "Epoch 405/500: loss: 0.03399, val_loss: 0.01563, val_accuracy: 0.99595\n",
      "Epoch 406/500: loss: 0.03311, val_loss: 0.01491, val_accuracy: 0.99595\n",
      "Epoch 407/500: loss: 0.03361, val_loss: 0.01425, val_accuracy: 0.99690\n",
      "Epoch 408/500: loss: 0.03313, val_loss: 0.01436, val_accuracy: 0.99619\n",
      "Epoch 409/500: loss: 0.03417, val_loss: 0.01468, val_accuracy: 0.99595\n",
      "Epoch 410/500: loss: 0.03182, val_loss: 0.01515, val_accuracy: 0.99643\n",
      "Epoch 411/500: loss: 0.03298, val_loss: 0.01496, val_accuracy: 0.99619\n",
      "Epoch 412/500: loss: 0.03225, val_loss: 0.01656, val_accuracy: 0.99548\n",
      "Epoch 413/500: loss: 0.03368, val_loss: 0.01639, val_accuracy: 0.99595\n",
      "Epoch 414/500: loss: 0.03444, val_loss: 0.01469, val_accuracy: 0.99595\n",
      "Epoch 415/500: loss: 0.03067, val_loss: 0.01593, val_accuracy: 0.99667\n",
      "Epoch 416/500: loss: 0.03214, val_loss: 0.01666, val_accuracy: 0.99619\n",
      "Epoch 417/500: loss: 0.03325, val_loss: 0.01584, val_accuracy: 0.99619\n",
      "Epoch 418/500: loss: 0.03285, val_loss: 0.01668, val_accuracy: 0.99619\n",
      "Epoch 419/500: loss: 0.03268, val_loss: 0.01623, val_accuracy: 0.99571\n",
      "Epoch 420/500: loss: 0.03411, val_loss: 0.01647, val_accuracy: 0.99619\n",
      "Epoch 421/500: loss: 0.03336, val_loss: 0.01712, val_accuracy: 0.99619\n",
      "Epoch 422/500: loss: 0.03508, val_loss: 0.01769, val_accuracy: 0.99595\n",
      "Epoch 423/500: loss: 0.03327, val_loss: 0.01641, val_accuracy: 0.99595\n",
      "Epoch 424/500: loss: 0.03068, val_loss: 0.01620, val_accuracy: 0.99643\n",
      "Epoch 425/500: loss: 0.03150, val_loss: 0.01732, val_accuracy: 0.99571\n",
      "Epoch 426/500: loss: 0.03130, val_loss: 0.01531, val_accuracy: 0.99619\n",
      "Epoch 427/500: loss: 0.03380, val_loss: 0.01741, val_accuracy: 0.99595\n",
      "Epoch 428/500: loss: 0.03248, val_loss: 0.01627, val_accuracy: 0.99571\n",
      "Epoch 429/500: loss: 0.03526, val_loss: 0.01571, val_accuracy: 0.99595\n",
      "Epoch 430/500: loss: 0.02871, val_loss: 0.01597, val_accuracy: 0.99571\n",
      "Epoch 431/500: loss: 0.03227, val_loss: 0.01605, val_accuracy: 0.99571\n",
      "Epoch 432/500: loss: 0.03351, val_loss: 0.01734, val_accuracy: 0.99595\n",
      "Epoch 433/500: loss: 0.03353, val_loss: 0.01639, val_accuracy: 0.99595\n",
      "Epoch 434/500: loss: 0.03358, val_loss: 0.01672, val_accuracy: 0.99524\n",
      "Epoch 435/500: loss: 0.03272, val_loss: 0.01710, val_accuracy: 0.99500\n",
      "Epoch 436/500: loss: 0.03383, val_loss: 0.01603, val_accuracy: 0.99500\n",
      "Epoch 437/500: loss: 0.03077, val_loss: 0.01558, val_accuracy: 0.99571\n",
      "Epoch 438/500: loss: 0.03179, val_loss: 0.01568, val_accuracy: 0.99524\n",
      "Epoch 439/500: loss: 0.03429, val_loss: 0.01368, val_accuracy: 0.99571\n",
      "Epoch 440/500: loss: 0.03247, val_loss: 0.01502, val_accuracy: 0.99548\n",
      "Epoch 441/500: loss: 0.03168, val_loss: 0.01537, val_accuracy: 0.99571\n",
      "Epoch 442/500: loss: 0.03167, val_loss: 0.01548, val_accuracy: 0.99548\n",
      "Epoch 443/500: loss: 0.03323, val_loss: 0.01665, val_accuracy: 0.99595\n",
      "Epoch 444/500: loss: 0.03164, val_loss: 0.01567, val_accuracy: 0.99619\n",
      "Epoch 445/500: loss: 0.03252, val_loss: 0.01482, val_accuracy: 0.99595\n",
      "Epoch 446/500: loss: 0.03314, val_loss: 0.01628, val_accuracy: 0.99571\n",
      "Epoch 447/500: loss: 0.03242, val_loss: 0.01420, val_accuracy: 0.99595\n",
      "Epoch 448/500: loss: 0.03494, val_loss: 0.01525, val_accuracy: 0.99619\n",
      "Epoch 449/500: loss: 0.03358, val_loss: 0.01586, val_accuracy: 0.99619\n",
      "Epoch 450/500: loss: 0.03412, val_loss: 0.01587, val_accuracy: 0.99548\n",
      "Epoch 451/500: loss: 0.03377, val_loss: 0.01550, val_accuracy: 0.99571\n",
      "Epoch 452/500: loss: 0.03176, val_loss: 0.01463, val_accuracy: 0.99595\n",
      "Epoch 453/500: loss: 0.03288, val_loss: 0.01502, val_accuracy: 0.99524\n",
      "Epoch 454/500: loss: 0.03420, val_loss: 0.01593, val_accuracy: 0.99595\n",
      "Epoch 455/500: loss: 0.03481, val_loss: 0.01537, val_accuracy: 0.99571\n",
      "Epoch 456/500: loss: 0.03075, val_loss: 0.01599, val_accuracy: 0.99595\n",
      "Epoch 457/500: loss: 0.03340, val_loss: 0.01628, val_accuracy: 0.99619\n",
      "Epoch 458/500: loss: 0.03156, val_loss: 0.01561, val_accuracy: 0.99619\n",
      "Epoch 459/500: loss: 0.03224, val_loss: 0.01499, val_accuracy: 0.99595\n",
      "Epoch 460/500: loss: 0.03465, val_loss: 0.01516, val_accuracy: 0.99595\n",
      "Epoch 461/500: loss: 0.03217, val_loss: 0.01661, val_accuracy: 0.99619\n",
      "Epoch 462/500: loss: 0.03123, val_loss: 0.01466, val_accuracy: 0.99571\n",
      "Epoch 463/500: loss: 0.02968, val_loss: 0.01628, val_accuracy: 0.99619\n",
      "Epoch 464/500: loss: 0.03353, val_loss: 0.01509, val_accuracy: 0.99595\n",
      "Epoch 465/500: loss: 0.03341, val_loss: 0.01624, val_accuracy: 0.99524\n",
      "Epoch 466/500: loss: 0.03159, val_loss: 0.01534, val_accuracy: 0.99571\n",
      "Epoch 467/500: loss: 0.03256, val_loss: 0.01389, val_accuracy: 0.99595\n",
      "Epoch 468/500: loss: 0.03021, val_loss: 0.01395, val_accuracy: 0.99571\n",
      "Epoch 469/500: loss: 0.03245, val_loss: 0.01431, val_accuracy: 0.99595\n",
      "Epoch 470/500: loss: 0.03145, val_loss: 0.01597, val_accuracy: 0.99571\n",
      "Epoch 471/500: loss: 0.03374, val_loss: 0.01463, val_accuracy: 0.99500\n",
      "Epoch 472/500: loss: 0.03129, val_loss: 0.01700, val_accuracy: 0.99500\n",
      "Epoch 473/500: loss: 0.03490, val_loss: 0.01392, val_accuracy: 0.99500\n",
      "Epoch 474/500: loss: 0.03098, val_loss: 0.01444, val_accuracy: 0.99571\n",
      "Epoch 475/500: loss: 0.03190, val_loss: 0.01434, val_accuracy: 0.99595\n",
      "Epoch 476/500: loss: 0.03375, val_loss: 0.01384, val_accuracy: 0.99548\n",
      "Epoch 477/500: loss: 0.03224, val_loss: 0.01527, val_accuracy: 0.99524\n",
      "Epoch 478/500: loss: 0.03383, val_loss: 0.01448, val_accuracy: 0.99595\n",
      "Epoch 479/500: loss: 0.03256, val_loss: 0.01623, val_accuracy: 0.99524\n",
      "Epoch 480/500: loss: 0.03259, val_loss: 0.01665, val_accuracy: 0.99524\n",
      "Epoch 481/500: loss: 0.03063, val_loss: 0.01598, val_accuracy: 0.99571\n",
      "Epoch 482/500: loss: 0.03019, val_loss: 0.01337, val_accuracy: 0.99619\n",
      "Epoch 483/500: loss: 0.02928, val_loss: 0.01510, val_accuracy: 0.99619\n",
      "Epoch 484/500: loss: 0.03243, val_loss: 0.01493, val_accuracy: 0.99571\n",
      "Epoch 485/500: loss: 0.02970, val_loss: 0.01521, val_accuracy: 0.99595\n",
      "Epoch 486/500: loss: 0.03203, val_loss: 0.01631, val_accuracy: 0.99595\n",
      "Epoch 487/500: loss: 0.03350, val_loss: 0.01598, val_accuracy: 0.99571\n",
      "Epoch 488/500: loss: 0.03273, val_loss: 0.01509, val_accuracy: 0.99643\n",
      "Epoch 489/500: loss: 0.03150, val_loss: 0.01546, val_accuracy: 0.99619\n",
      "Epoch 490/500: loss: 0.03307, val_loss: 0.01584, val_accuracy: 0.99571\n",
      "Epoch 491/500: loss: 0.02960, val_loss: 0.01454, val_accuracy: 0.99571\n",
      "Epoch 492/500: loss: 0.02997, val_loss: 0.01384, val_accuracy: 0.99619\n",
      "Epoch 493/500: loss: 0.03035, val_loss: 0.01561, val_accuracy: 0.99571\n",
      "Epoch 494/500: loss: 0.03074, val_loss: 0.01612, val_accuracy: 0.99476\n",
      "Epoch 495/500: loss: 0.03332, val_loss: 0.01630, val_accuracy: 0.99571\n",
      "Epoch 496/500: loss: 0.03190, val_loss: 0.01421, val_accuracy: 0.99571\n",
      "Epoch 497/500: loss: 0.03038, val_loss: 0.01641, val_accuracy: 0.99548\n",
      "Epoch 498/500: loss: 0.03224, val_loss: 0.01695, val_accuracy: 0.99619\n",
      "Epoch 499/500: loss: 0.03142, val_loss: 0.01605, val_accuracy: 0.99643\n",
      "Epoch 500/500: loss: 0.03280, val_loss: 0.01488, val_accuracy: 0.99571\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    dataset = data.batch(batch_size, drop_remainder = False)\n",
    "    loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in dataset:\n",
    "        loss += train_step(X_batch, y_batch) * len(X_batch)\n",
    "        \n",
    "    loss /= len(X_train)\n",
    "\n",
    "    val_loss = test_step(X_valid, y_valid)\n",
    "    val_accuracy = (np.argmax(model(X_valid), 1) == np.array(y_valid)).mean()  \n",
    "    \n",
    "    print(f\"Epoch {epoch}/{EPOCHS}: loss: {loss:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67900901",
   "metadata": {
    "papermill": {
     "duration": 0.045346,
     "end_time": "2023-12-03T15:55:00.467871",
     "exception": false,
     "start_time": "2023-12-03T15:55:00.422525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Putting the model in inference mode and passing the test data in batches to support GPU's memory limitations and then creating a submission that complies to the kaggle competition format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4842dd5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:55:00.559855Z",
     "iopub.status.busy": "2023-12-03T15:55:00.559523Z",
     "iopub.status.idle": "2023-12-03T15:55:02.289924Z",
     "shell.execute_reply": "2023-12-03T15:55:02.289110Z"
    },
    "papermill": {
     "duration": 1.779195,
     "end_time": "2023-12-03T15:55:02.292343",
     "exception": false,
     "start_time": "2023-12-03T15:55:00.513148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.training = False\n",
    "y_pred = []\n",
    "\n",
    "for i in range(0, len(X_test)-100+1, 100):\n",
    "    partial = np.argmax(model(X_test[i:i+100]), axis = 1)\n",
    "    y_pred.append(partial)\n",
    "    \n",
    "y_pred = np.array(y_pred).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19776f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T15:55:02.386146Z",
     "iopub.status.busy": "2023-12-03T15:55:02.385534Z",
     "iopub.status.idle": "2023-12-03T15:55:02.693794Z",
     "shell.execute_reply": "2023-12-03T15:55:02.692990Z"
    },
    "papermill": {
     "duration": 0.356639,
     "end_time": "2023-12-03T15:55:02.695933",
     "exception": false,
     "start_time": "2023-12-03T15:55:02.339294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_id = np.arange(start = 1, stop = y_pred.shape[0]+1)\n",
    "\n",
    "submission = pd.DataFrame(zip(image_id,y_pred), columns = [\"ImageId\",\"label\"])\n",
    "submission.set_index(\"ImageId\",inplace = True)\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 312.874394,
   "end_time": "2023-12-03T15:55:05.725754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T15:49:52.851360",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
